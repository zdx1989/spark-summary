package sparkcore

/**
  * Created by zhoudunxiong on 2018/7/25.
  */
object SparkScheduler {

  def main(args: Array[String]): Unit = {

    //Worker的分配策略，一种是把应用尽可能的分配到多的worker上，该策略能够充分利用集群的资源，并有利于数据的本地行处理了
    //另一种是把应用程序运行在尽可能少的worker上，适用于CPU密集型的场景
    //该策略由spark.deploy.spreadOut配置项控制，默认为true，即尽可能分散

    //job之间的调度策略：一种是FIFO模式，这也是默认的模式；
    // 一种是FAIR模式，由minShare（最小任务数）和weight（任务权重）来决定job执行的优先级

    //FIFO，首先比较job的编号，编号越小优先级越高，job编号一样，然后比较stage的优先级，stage编号越小，优先级越高
    //fairscheduler.xml
    //调度的饥饿程度， 正在运行的任务数是否小于最小任务数，假如小于说明调度正处于饥饿状态
    //调度策略
    //优先满足饥饿状态的调度
    //都是饥饿状态，优先满足资源小的调度
    //都是非饥饿状态，优先满足权重比小的
    //都相同，则根据调度的名称排序


    //任务之间的调度， 数据本地行和延迟执行
    //数据本地行，数据的计算尽可能在数据所在的节点上运行，避免数据在网上传输
    //数据本地行的优先级：Process_local > Node_Local > No_Pref > Rack_Local > Any
    //Rdd分区的首先位置也是任务运行的首选位置，本地行为Node_local
    //由父调度阶段决定任务的首选位置

    //延迟执行
    //先判断任务本地性优先级最高的节点是否由足够的资源运行任务，如果没有会等待一段时间延迟执行，
    //假如等待时间过后还没有足够的资源，任务会选择本地行优先级次高的节点，默认等待的时间是3秒
  }
}
